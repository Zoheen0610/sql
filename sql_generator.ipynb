{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOm85b4FamFUbxzj4N87gZi",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sharik31/SQL-Generator/blob/main/sql_generator.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rho9LZkSlvKG"
      },
      "outputs": [],
      "source": [
        "!pip install transformers datasets peft bitsandbytes accelerate\n",
        "!pip uninstall -y transformers accelerate\n",
        "!pip install -U \"transformers>=4.41.0\" \"accelerate>=0.33.0\" \"datasets>=2.20.0\" evaluate peft bitsandbytes\n",
        "!pip install -U transformers datasets peft accelerate trl\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer, BitsAndBytesConfig\n",
        "\n",
        "model_name = \"t5-small\"\n",
        "\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_compute_dtype=\"float16\"\n",
        ")\n",
        "\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(\n",
        "    model_name,\n",
        "    quantization_config=bnb_config,\n",
        "    device_map=\"auto\"\n",
        ")\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n"
      ],
      "metadata": {
        "id": "x44AOYF_l3zP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from peft import LoraConfig, get_peft_model\n",
        "\n",
        "lora_config = LoraConfig(\n",
        "    r=8,\n",
        "    lora_alpha=16,\n",
        "    target_modules=[\"q\", \"v\"],\n",
        "    lora_dropout=0.05,\n",
        "    bias=\"none\",\n",
        "    task_type=\"SEQ_2_SEQ_LM\"\n",
        "\n",
        "model = get_peft_model(model, lora_config)\n"
      ],
      "metadata": {
        "id": "_rvDp20umBhs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "dataset = load_dataset(\n",
        "    \"csv\",\n",
        "    data_files={\n",
        "        \"train\": \"/content/WikiSQL.csv\",\n",
        "        \"validation\": \"/content/Wikisql_val.csv\",\n",
        "        \"test\": \"/content/Wikisql_test.csv\"\n",
        "    }\n",
        ")\n",
        "\n",
        "def preprocess(examples):\n",
        "    inputs = tokenizer(examples[\"question\"], truncation=True, padding=\"max_length\", max_length=128)\n",
        "    labels = tokenizer(examples[\"sql\"], truncation=True, padding=\"max_length\", max_length=128)\n",
        "    inputs[\"labels\"] = labels[\"input_ids\"]\n",
        "    return inputs\n",
        "\n",
        "tokenized_dataset = dataset.map(preprocess, batched=True)\n"
      ],
      "metadata": {
        "id": "SMJd7RlSmKdS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import Seq2SeqTrainingArguments\n",
        "from transformers import Seq2SeqTrainer\n"
      ],
      "metadata": {
        "id": "42ig1s8u1j04"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_args = Seq2SeqTrainingArguments(\n",
        "    output_dir=\"./results\",\n",
        "    per_device_train_batch_size=4,\n",
        "    per_device_eval_batch_size=4,\n",
        "    learning_rate=5e-5,\n",
        "    num_train_epochs=1,\n",
        "    weight_decay=0.01,\n",
        "    save_total_limit=2,\n",
        "    predict_with_generate=True,\n",
        "    logging_dir=\"./logs\",\n",
        "    use_legacy_prediction_loop=False,\n",
        ")"
      ],
      "metadata": {
        "id": "3JYciHWyra5K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import DataCollatorForSeq2Seq\n",
        "\n",
        "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model, return_tensors=\"pt\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "6E9CK7mvyZWD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = Seq2SeqTrainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_dataset[\"train\"],\n",
        "    eval_dataset=tokenized_dataset[\"validation\"],\n",
        "    processing_class=tokenizer,\n",
        "    data_collator=data_collator\n",
        ")\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "d1DrDt8qqPhI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()"
      ],
      "metadata": {
        "id": "vzEJ2J_3zemL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save_pretrained(\"lora_sql_model\")\n"
      ],
      "metadata": {
        "id": "m3tEL5sfYrxi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"Retrieve all rolls from the student table.\"\n",
        "tables = \"ADMIN: USERNAME (PRIMARY KEY) (text); PASS (text); STUDENT: roll (PRIMARY KEY) (int), name (text), dept (text)\"\n",
        "\n",
        "input_text = \"Here is schema details: \" + tables + \" Answer this question as an SQL query: \" + question\n",
        "\n",
        "inputs = tokenizer(input_text, return_tensors=\"pt\", truncation=True, max_length=1024).to(device)\n",
        "outputs = model.generate(**inputs, max_length=512)\n",
        "sql_query = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "print(\"Predicted SQL:\", sql_query)\n"
      ],
      "metadata": {
        "id": "fcrhmmLNcLCS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "from peft import PeftModel\n",
        "import torch\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "base_model_name = \"t5-small\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(base_model_name)\n",
        "base_model = AutoModelForSeq2SeqLM.from_pretrained(base_model_name, device_map=\"auto\")\n",
        "\n",
        "model = PeftModel.from_pretrained(base_model, \"lora_sql_model\", device_map=\"auto\")\n",
        "model.eval()"
      ],
      "metadata": {
        "id": "IrAIRR0UftX4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "import torch\n",
        "\n",
        "df_test = pd.read_csv(\"/content/Wikisql_test.csv\")\n",
        "\n",
        "df_test = df_test.iloc[:1000]\n",
        "\n",
        "inputs = df_test['question'].tolist()\n",
        "labels = df_test['sql'].tolist()\n",
        "\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model.to(device)\n",
        "\n",
        "\n",
        "batch_size = 16\n",
        "generated_sql_queries = []\n",
        "\n",
        "for i in tqdm(range(0, len(inputs), batch_size)):\n",
        "    batch_texts = inputs[i:i+batch_size]\n",
        "\n",
        "    input_tensor = tokenizer(batch_texts,\n",
        "                             return_tensors=\"pt\",\n",
        "                             truncation=True,\n",
        "                             padding=True,\n",
        "                             max_length=1024).to(device)\n",
        "\n",
        "    outputs = model.generate(**input_tensor, max_length=512)\n",
        "\n",
        "\n",
        "    batch_sql = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
        "    generated_sql_queries.extend(batch_sql)\n",
        "\n",
        "for i in range(10):\n",
        "    print(f\"Question: {inputs[i]}\")\n",
        "    print(f\"Predicted SQL: {generated_sql_queries[i]}\")\n",
        "    print(f\"Ground Truth SQL: {labels[i]}\")\n",
        "    print(\"-\"*40)\n",
        "\n"
      ],
      "metadata": {
        "id": "UD-9kb9thXSf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "zxl2Se0gfnhY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "import evaluate\n",
        "\n",
        "nltk.download(\"punkt\", quiet=True)\n",
        "nltk.download(\"punkt_tab\", quiet=True)\n",
        "rouge = evaluate.load(\"rouge\")\n",
        "decoded_preds = [\"\\n\".join(nltk.sent_tokenize(p.strip())) for p in generated_sql_queries]\n",
        "decoded_labels = [\"\\n\".join(nltk.sent_tokenize(l.strip())) for l in labels]\n",
        "rouge_score = rouge.compute(predictions=decoded_preds, references=decoded_labels, use_stemmer=True)\n",
        "\n",
        "print(\"\\nROUGE Score on Test Set:\")\n",
        "print(rouge_score)"
      ],
      "metadata": {
        "id": "B8-MBL90lhXn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "55a4abcd"
      },
      "source": [
        "!pip install rouge_score"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}